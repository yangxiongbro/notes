# Hadoop

## 相关概念

### HDFS

Hadoop Distributed File System，Hadoop 分布式文件系统，简称 HDFS。

**命名节点 (NameNode)**

​		命名节点 (NameNode) 是用于指挥其它节点存储的节点。任何一个"文件系统"(File System, FS) 都需要具备根据文件路径映射到文件的功能，命名节点就是用于储存这些映射信息并提供映射服务的计算机，在整个 HDFS 系统中扮演"管理员"的角色，因此一个 HDFS 集群中只有一个命名节点。

**数据节点 (DataNode)**

​		数据节点 (DataNode) 使用来储存数据块的节点。当一个文件被命名节点承认并分块之后将会被储存到被分配的数据节点中去。数据节点具有储存数据、读写数据的功能，其中存储的数据块比较类似于硬盘中的"扇区"概念，是 HDFS 存储的基本单位。

**副命名节点 (Secondary NameNode)**

​		副命名节点 (Secondary NameNode) 别名"次命名节点"，是命名节点的"秘书"。这个形容很贴切，因为它并不能代替命名节点的工作，无论命名节点是否有能力继续工作。它主要负责分摊命名节点的压力、备份命名节点的状态并执行一些管理工作，如果命名节点要求它这样做的话。如果命名节点坏掉了，它也可以提供备份数据以恢复命名节点。副命名节点可以有多个。

![](../pictures/202507/20250709_001.png)





### MapReduce

MapReduce 的含义就像它的名字一样浅显：Map 和 Reduce (映射和规约) 



## 安装配置

[Apache Hadoop](https://hadoop.apache.org/releases.html)

3.4.x 只支持Java 8和Java 11

### 前置环境

```shell
# Java 运行环境
scp H:\Packages\Linux\Java\jdk-8u321-linux-i586.tar.gz young@192.168.31.101:/home/young/packages/
sudo tar -zxvf /home/young/packages/jdk-8u321-linux-i586.tar.gz -C /opt/apps/
sudo mv /opt/apps/jdk1.8.0_321 /opt/apps/jdk1.8.0

# SSH 环境
systemctl enable ssh && systemctl start ssh
```

```shell
scp E:\Need2Sync\Packages\Linux\Hadoop\hadoop-3.4.1.tar.gz young@192.168.31.101:/home/young/packages/

cd /opt/apps/
sudo tar -zxvf /home/young/packages/hadoop-3.4.1.tar.gz -C ./
sudo mv hadoop-3.4.1 hadoop

# 配置环境变量
sudo vim /etc/profile
# export HADOOP_HOME="/opt/apps/hadoop"
# export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
source /etc/profile

# 是否成功
hadoop version
# Hadoop 3.4.1
# Source code repository https://github.com/apache/hadoop.git -r 4d7825309348956336b8f06a08322b78422849b1
# Compiled by mthakur on 2024-10-09T14:57Z
# Compiled on platform linux-x86_64
# Compiled with protoc 3.23.4
# From source with checksum 7292fe9dba5e2e44e3a9f763fce3e680
# This command was run using /opt/apps/hadoop/share/hadoop/common/hadoop-common-3.4.1.jar

# 创建运行 Hadoop 的用户
sudo useradd -s /bin/bash -m hadoop
sudo passwd hadoop

sudo mkdir /opt/data/hadoop
sudo chown -R hadoop /opt/apps/hadoop
sudo chown -R hadoop /opt/data/hadoop

# 配置管理员权限
sudo vim /etc/sudoers
hadoop  ALL=(ALL)       ALL
```



### 配置

- workers	记录所有的数据节点的主机名或 IP 地址
- core-site.xml	Hadoop 核心配置
- hdfs-site.xml	HDFS 配置项
- mapred-site.xml	MapReduce 配置项
- yarn-site.xml	YARN 配置项，为 MapReduce 提供资源管理服务



`cd $HADOOP_HOME/etc/hadoop`

#### 命名节点

workers

`sudo vim workers `

```shell
192.168.31.102
192.168.31.103
```



core-site.xml

`sudo vim core-site.xml `

```xml
    <!-- 配置 HDFS 主机地址与端口号 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://192.168.31.101:9000</value>
    </property>
    <!-- 配置 Hadoop 的临时文件目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:///opt/data/hadoop/tmp</value>
    </property>
```



hdfs-site.xml

`sudo vim hdfs-site.xml `

```xml
    <!-- 每个数据块复制 2 份存储 -->
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    
    <!-- 设置储存命名信息的目录 -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/data/hadoop/hdfs/name</value>
    </property>
```



hadoop-env.sh

`sudo vim hadoop-env.sh`

`JAVA_HOME=/opt/apps/jdk1.8.0`



```shell
su hadoop
# 其中一台机器生成 SSH 密钥
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa

scp ~/.ssh/id_rsa hadoop@192.168.31.102:/home/hadoop/.ssh/
scp ~/.ssh/id_rsa.pub hadoop@192.168.31.102:/home/hadoop/.ssh/
scp ~/.ssh/id_rsa hadoop@192.168.31.103:/home/hadoop/.ssh/
scp ~/.ssh/id_rsa.pub hadoop@192.168.31.103:/home/hadoop/.ssh/

# 密钥添加到信任列表
# 所有机器执行
ssh-copy-id -i ~/.ssh/id_rsa hadoop@localhost
```




### 启动

```shell
su hadoop

# 进入命名节点
# 格式化 HDFS
hdfs namenode -format

# 启动 HDFS
start-dfs.sh
stop-dfs.sh
# 启动分三个步骤，分别启动 NameNode、DataNode 和 Secondary NameNode
# 命名节点不存在 DataNode 进程
# 运行 jps 查看 Java 进程
```

