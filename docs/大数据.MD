# Hadoop

Hadoop 是一个开源的分布式计算和存储框架，由 Apache 基金会开发和维护。

## 相关概念

### HDFS

Hadoop Distributed File System，Hadoop 分布式文件系统，简称 HDFS。

**命名节点 (NameNode)**

​		命名节点 (NameNode) 是用于指挥其它节点存储的节点。任何一个"文件系统"(File System, FS) 都需要具备根据文件路径映射到文件的功能，命名节点就是用于储存这些映射信息并提供映射服务的计算机，在整个 HDFS 系统中扮演"管理员"的角色，因此一个 HDFS 集群中只有一个命名节点。

**数据节点 (DataNode)**

​		数据节点 (DataNode) 使用来储存数据块的节点。当一个文件被命名节点承认并分块之后将会被储存到被分配的数据节点中去。数据节点具有储存数据、读写数据的功能，其中存储的数据块比较类似于硬盘中的"扇区"概念，是 HDFS 存储的基本单位。

**副命名节点 (Secondary NameNode)**

​		副命名节点 (Secondary NameNode) 别名"次命名节点"，是命名节点的"秘书"。这个形容很贴切，因为它并不能代替命名节点的工作，无论命名节点是否有能力继续工作。它主要负责分摊命名节点的压力、备份命名节点的状态并执行一些管理工作，如果命名节点要求它这样做的话。如果命名节点坏掉了，它也可以提供备份数据以恢复命名节点。副命名节点可以有多个。

![](../pictures/202507/20250709_001.png)





### MapReduce

MapReduce 的含义就像它的名字一样浅显：Map 和 Reduce (映射和规约) 



## 安装配置

[Apache Hadoop](https://hadoop.apache.org/releases.html)

3.4.x 只支持Java 8和Java 11

### 前置环境

```shell
# Java 运行环境
scp H:\Packages\Linux\Java\jdk-8u441-linux-x64.tar.gz young@192.168.31.101:/home/young/packages/
sudo tar -zxvf /home/young/packages/jdk-8u441-linux-x64.tar.gz -C /opt/apps/
sudo mv /opt/apps/jdk1.8.0_441 /opt/apps/jdk1.8.0

# SSH 环境
systemctl enable ssh && systemctl start ssh
```



### 文件部署

```shell
scp E:\Need2Sync\Packages\Linux\Hadoop\hadoop-3.4.1.tar.gz young@192.168.31.101:/home/young/packages/

cd /opt/apps/
sudo tar -zxvf /home/young/packages/hadoop-3.4.1.tar.gz -C ./
sudo mv hadoop-3.4.1 hadoop

# 配置环境变量
sudo vim /etc/profile
# export HADOOP_HOME="/opt/apps/hadoop"
# export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
source /etc/profile

# 是否成功
hadoop version
# Hadoop 3.4.1
# Source code repository https://github.com/apache/hadoop.git -r 4d7825309348956336b8f06a08322b78422849b1
# Compiled by mthakur on 2024-10-09T14:57Z
# Compiled on platform linux-x86_64
# Compiled with protoc 3.23.4
# From source with checksum 7292fe9dba5e2e44e3a9f763fce3e680
# This command was run using /opt/apps/hadoop/share/hadoop/common/hadoop-common-3.4.1.jar

# 创建运行 Hadoop 的用户
sudo useradd -r -g apps -s /bin/bash -m hadoop
sudo passwd hadoop

sudo mkdir /opt/data/hadoop
sudo mkdir /opt/temp/hadoop
sudo chown -R hadoop:apps /opt/apps/hadoop
sudo chown -R hadoop:apps /opt/data/hadoop
sudo chown -R hadoop:apps /opt/temp/hadoop

# 配置管理员权限
sudo vim /etc/sudoers
hadoop  ALL=(ALL)       ALL
```



### 配置

- workers	记录所有的数据节点的主机名或 IP 地址
- core-site.xml	Hadoop 核心配置
- hdfs-site.xml	HDFS 配置项
- mapred-site.xml	MapReduce 配置项
- yarn-site.xml	YARN 配置项，为 MapReduce 提供资源管理服务



在每个节点进行以下配置



#### workers

`vim $HADOOP_HOME/etc/hadoop/workers `

```shell
192.168.31.102
192.168.31.103
```



#### core-site.xml

`vim $HADOOP_HOME/etc/hadoop/core-site.xml `

```xml
    <!-- 配置 HDFS 主机地址与端口号 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://192.168.31.101:9000</value>
    </property>
    <!-- 配置 Hadoop 的临时文件目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:///opt/data/hadoop/tmp</value>
    </property>
```



#### hdfs-site.xml

`vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml `

```xml
    <!-- 每个数据块复制 2 份存储 -->
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    
    <!-- 设置储存命名信息的目录 -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///opt/data/hadoop/hdfs/name</value>
    </property>
```



#### hadoop-env.sh

`vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh`

```shell
export JAVA_HOME=/opt/apps/jdk1.8.0
export HADOOP_PID_DIR=/opt/temp/hadoop

# NameNode 内存限制
export HDFS_NAMENODE_OPTS="-Xmx4g -Xms4g"

# DataNode 内存限制
export HDFS_DATANODE_OPTS="-Xmx2g -Xms2g"

# ResourceManager 内存限制
export YARN_RESOURCEMANAGER_OPTS="-Xmx2g -Xms2g"

# NodeManager 内存限制
export YARN_NODEMANAGER_OPTS="-Xmx2g -Xms2g"

# 历史服务器内存
export MAPRED_HISTORYSERVER_OPTS="-Xmx2g"
```



### 设置SSH免密登录

```shell
su hadoop
# 在NameNode上生成密钥对
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
# 并将公钥复制到所有节点（包括自己）
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@localhost
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@192.168.31.102
ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@192.168.31.103

# 测试，应该不需要密码
ssh hadoop@192.168.31.102
```



### 初始化

```shell
# 在命名节点中

su hadoop

# 格式化 HDFS
hdfs namenode -format
```



### 服务管理

#### 启动

```shell
# 只需要在在NameNode启动 HDFS，会在NameNode启动NameNode\Secondary NameNode，自动远程启动其它两台DataNode启动DataNode
$HADOOP_HOME/sbin/start-dfs.sh
$HADOOP_HOME/sbin/stop-dfs.sh
# 启动分三个步骤，分别启动 NameNode、DataNode 和 Secondary NameNode
# 命名节点不存在 DataNode 进程
# 运行 jps 查看 Java 进程
```



#### systemctl 

1、创建启动脚本

`vim /home/hadoop/start-dfs.sh.simple`

`sudo chmod +x /home/hadoop/start-dfs.sh.simple`

```shell
#!/bin/bash

/opt/apps/hadoop/sbin/start-dfs.sh
PID_FILE="/opt/temp/hadoop/hadoop-hadoop-namenode.pid"

sleep 5

while true; do
    # 检查文件是否存在且有内容
    if [[ -f "$PID_FILE" && -s "$PID_FILE" ]]; then
        # echo "文件已准备就绪"
        sleep 10
    else
		exit 0
    fi
done

exit 1
```



2、配置 systemctl 服务

`sudo vim /etc/systemd/system/hadoop.service`

[hadoop.service](../files/scripts/server/hadoop.service)



#### 服务管理命令

```shell
# 检查语法错误
systemd-analyze verify /etc/systemd/system/hadoop.service
# 重载 systemd 配置
sudo systemctl daemon-reload
# 设置开机自启
sudo systemctl enable hadoop

# 启动
sudo systemctl start hadoop
# 停止
sudo systemctl stop hadoop
# 查看状态
sudo systemctl status hadoop
```



# Flink



## 相关概念





## 安装配置

[Downloads | Apache Flink](https://flink.apache.org/zh/downloads/)

### Standalone-HA

#### 规划

服务器01： JobManager+TaskManager

服务器02： JobManager+TaskManager

服务器03： TaskManager



#### 文件部署

```shell
scp E:\Need2Sync\Packages\Linux\Flink\flink-1.20.2-bin-scala_2.12.tgz young@192.168.31.101:/home/young/packages/

cd /opt/apps/
sudo tar -zxf /home/young/packages/flink-1.20.2-bin-scala_2.12.tgz -C ./
sudo mv flink-1.20.2 flink

# 创建运行 Hadoop 的用户
sudo useradd -r -g apps -s /bin/bash -m flink
sudo passwd flink

sudo mkdir -p /opt/data/flink/{checkpoints,savepoints,ha,logs}
sudo mkdir /opt/temp/flink
sudo chown -R flink:apps /opt/apps/flink
sudo chown -R flink:apps /opt/data/flink
sudo chown -R flink:apps /opt/temp/flink

# 配置管理员权限
sudo vim /etc/sudoers
flink  ALL=(ALL)       ALL
```



#### 配置

##### flink-conf.yaml

`vim /opt/apps/flink/conf/flink-conf.yaml`

```yaml
# 基础配置
# These parameters are required for Java 17 support.
# They can be safely removed when using Java 8/11.
env.java.opts.all: --add-exports=java.base/sun.net.util=ALL-UNNAMED --add-exports=java.rmi/sun.rmi.registry=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.api=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED --add-exports=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED --add-exports=java.security.jgss/sun.security.krb5=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.text=ALL-UNNAMED --add-opens=java.base/java.time=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.locks=ALL-UNNAMED

env.pid.dir: /opt/temp/flink

# 配置高可用居群不需要配置 jobmanager.rpc.address，由ZK动态分配
# jobmanager.rpc.address: localhost
jobmanager.rpc.port: 6123
# jobmanager.bind-host: 0.0.0.0
jobmanager.memory.process.size: 1600m
# taskmanager.bind-host: 0.0.0.0
taskmanager.host: localhost
taskmanager.memory.process.size: 2048m
taskmanager.numberOfTaskSlots: 2
rest.address: 0.0.0.0
rest.port: 8081
parallelism.default: 2

# 高可用配置
high-availability: zookeeper
high-availability.storageDir: file:///opt/data/flink/ha
# high-availability.storageDir: hdfs://namenode:8020/flink/ha  # HA元数据存储路径
high-availability.zookeeper.quorum: 192.168.31.101:2181,192.168.31.102:2181,192.168.31.103:2181
# high-availability.zookeeper.path.root: /flink
high-availability.cluster-id: flink-cluster

# 检查点配置
state.backend: filesystem
state.checkpoints.dir: file:///opt/data/flink/checkpoints
# state.backend.fs.checkpointdir: hdfs://namenode:8020/flink/checkpoints
state.savepoints.dir: file:///opt/data/flink/savepoints
# state.backend.fs.savepointdir: hdfs://namenode:8020/flink/savepoints
# execution.checkpointing.interval: 10000

# 日志配置
# web.log.path: /data/flink/logs

# 安全配置（可选）
# security.ssl.internal.enabled: true
# security.ssl.internal.keystore: /opt/flink/conf/keystore.jks
# security.ssl.internal.truststore: /opt/flink/conf/truststore.jks
```



##### masters

配置 masters 文件（JobManager 节点）

`vim /opt/apps/flink/conf/masters `

```
192.168.31.101:8081
192.168.31.102:8081
```



##### workers

配置 workers 文件（TaskManager 节点）

`vim /opt/apps/flink/conf/workers `

```
192.168.31.101
192.168.31.102
192.168.31.103
```



#### 设置SSH免密登录

```shell
su flink
# 在其中一个节点生成密钥对
ssh-keygen -t rsa -P "" -f ~/.ssh/id_rsa
# 并将公钥复制到所有节点（包括自己）
ssh-copy-id -i ~/.ssh/id_rsa.pub flink@localhost
ssh-copy-id -i ~/.ssh/id_rsa.pub flink@192.168.31.102
ssh-copy-id -i ~/.ssh/id_rsa.pub flink@192.168.31.103

# 测试，应该不需要密码
ssh flink@192.168.31.102
```



#### 服务管理

##### 启动

```shell
# 只需要在JobManager，会在JobManager启动StandaloneSessionClusterEntrypoint\TaskManagerRunner
# 自动远程启动其它两台StandaloneSessionClusterEntrypoint\TaskManagerRunner
/opt/apps/flink/bin/start-cluster.sh
/opt/apps/flink/bin/stop-cluster.sh
```



##### systemctl

1、创建启动脚本

`vim /home/flink/start-cluster.sh.simple`

`sudo chmod +x /home/flink/start-cluster.sh.simple`

```shell
#!/bin/bash

/opt/apps/flink/bin/start-cluster.sh
PID_FILE="/opt/temp/flink/flink-flink-standalonesession.pid"

sleep 5

while true; do
    # 检查文件是否存在且有内容
    if [[ -f "$PID_FILE" && -s "$PID_FILE" ]]; then
        # echo "文件已准备就绪"
        sleep 10
    else
		exit 0
    fi
done

exit 1
```



2、配置 systemctl 服务

`sudo vim /etc/systemd/system/flink.service`

[flink.service](../files/scripts/server/flink.service)



##### 服务管理命令

```shell
# 检查语法错误
systemd-analyze verify /etc/systemd/system/flink.service
# 重载 systemd 配置
sudo systemctl daemon-reload
# 设置开机自启
sudo systemctl enable flink

# 启动
sudo systemctl start flink
# 停止
sudo systemctl stop flink
# 查看状态
sudo systemctl status flink
```



#### 测试

访问 WebUI

http://192.168.31.101:8081/#/job-manager/config



执行 WC

/opt/apps/flink/bin/flink run  /opt/apps/flink/examples/batch/WordCount.jar
